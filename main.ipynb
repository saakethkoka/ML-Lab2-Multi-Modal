{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 20:25:10.759467: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 20:25:11.871026: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.4.4-ctldo35wmmwws3jbgwkgjjcjawddu3qz/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/neovim-0.7.0-terkir3wk5rst6ktv4uxyaqjditacv5p/lib\n",
      "2023-02-24 20:25:11.871105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.4.4-ctldo35wmmwws3jbgwkgjjcjawddu3qz/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/neovim-0.7.0-terkir3wk5rst6ktv4uxyaqjditacv5p/lib\n",
      "2023-02-24 20:25:11.871113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "from IPython.display import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/work/users/skoka/Data/WikipediaImageCaptionsProccessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists all .json files in the data folder\n",
    "files = [f for f in os.listdir(DATA_FOLDER) if f.endswith('.json')]\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each json file has multiple json documents so we need to split them before loading\n",
    "def load_file_into_json(file):\n",
    "    with open(file) as f:\n",
    "        json_list = [json.loads(line) for line in f.read().splitlines()]\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file = load_file_into_json(DATA_FOLDER + files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/skoka/.venv/tensorflow/lib/python3.8/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/users/skoka/.venv/tensorflow/lib/python3.8/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Chat GPT parrallelized this code:\n",
    "def process_json_doc(json_doc):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    unlabeled_images = []\n",
    "\n",
    "    # Creating image from base64 bytes\n",
    "    image_bytes = json_doc['b64_bytes']\n",
    "    image_decoded = b64decode(image_bytes)\n",
    "    image = Image.open(BytesIO(image_decoded)).convert(\"RGB\") # Opens image from the decoded bytes\n",
    "    image = image.resize((250, 250)) # Resizes all images to 250x250 to remain consistent\n",
    "    image = np.array(image) # Converts image to numpy array\n",
    "\n",
    "    english_caption = \"\"\n",
    "    for caption in json_doc['wit_features']:\n",
    "        if caption[\"language\"] == \"en\":\n",
    "            try:\n",
    "                english_caption = caption[\"caption_reference_description\"]\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    if english_caption == \"\":\n",
    "        # decode base64 image\n",
    "        unlabeled_images.append(image)\n",
    "    else:\n",
    "        X_data.append(image)\n",
    "        y_data.append(english_caption)\n",
    "\n",
    "    return X_data, y_data, unlabeled_images\n",
    "\n",
    "def process_data(json_list):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    unlabeled_images = []\n",
    "\n",
    "    # Creating a pool of processes\n",
    "    pool = Pool()\n",
    "\n",
    "    # Processing each JSON document in parallel using the process_json_doc function\n",
    "    results = pool.map(process_json_doc, json_list)\n",
    "    \n",
    "    # Merging the results from each process\n",
    "    for result in results:\n",
    "        X_data += result[0]\n",
    "        y_data += result[1]\n",
    "        unlabeled_images += result[2]\n",
    "\n",
    "    # Converting the lists to numpy arrays\n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "    unlabeled_images = np.array(unlabeled_images)\n",
    "\n",
    "    return X_data, y_data, unlabeled_images\n",
    "\n",
    "X_data, y_data, _ = process_data(first_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5839, 250, 250, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT GENERATED\n",
    "def display_image_caption(image, caption):\n",
    "    # Convert the image to a PIL image\n",
    "    image = Image.fromarray(image)\n",
    "    # Display the image\n",
    "    display(image)\n",
    "    # Display the caption\n",
    "    print(caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
