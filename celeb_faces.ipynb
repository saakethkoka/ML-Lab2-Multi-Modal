{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 00:29:48.438641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 00:29:50.026649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.4.4-ctldo35wmmwws3jbgwkgjjcjawddu3qz/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/neovim-0.7.0-terkir3wk5rst6ktv4uxyaqjditacv5p/lib\n",
      "2023-03-06 00:29:50.026741: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.4.4-ctldo35wmmwws3jbgwkgjjcjawddu3qz/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/neovim-0.7.0-terkir3wk5rst6ktv4uxyaqjditacv5p/lib\n",
      "2023-03-06 00:29:50.026748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensorlfow work better with gpus:\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# eager execution:\n",
    "tf.compat.v1.enable_eager_execution(\n",
    "    config=None, device_policy=None, execution_mode=None\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Dataset\n",
    "\n",
    "What is the classification task and what is the format of the feature data. Is this multi-task, multi-modal, or both? Explain.\n",
    "Who collected the data? Why? When?\n",
    "What evaluation criteria will you be using and why? \n",
    "\n",
    "https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
    "\n",
    "We are using the IMDB-Wiki dataset for multi-task learning of Age and Gender from facial image data. We will be doing multi-task by training a model to classify geneder and regress age of a certain person based on their picture.\n",
    "\n",
    "\n",
    "This data was collecteted by \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "DATA_DIR = \"/work/users/skoka/Data/wiki_crop/\"\n",
    "META_DATA =  \"/work/users/skoka/Data/wiki_crop/wiki.mat\"\n",
    "\n",
    "PICKLES_PATH = \"/work/users/skoka/Data/wiki_crop_pickles/\"\n",
    "GET_IMAGES_FROM_PICKLE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from a .mat file\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "mat = sio.loadmat(META_DATA)\n",
    "# convert the data to a pandas dataframe\n",
    "mat_data = mat['wiki'][0][0]\n",
    "\n",
    "# 0 -> Matlab datatime format\n",
    "# 1 -> Years\n",
    "# 2 -> Path to image\n",
    "# 3 -> Gender\n",
    "\n",
    "# convert Matlab serial date number to datetime object\n",
    "def matlab_to_datetime(matlab_serial_date):\n",
    "    python_datetime = datetime.datetime.fromordinal(int(matlab_serial_date)) + \\\n",
    "                      datetime.timedelta(days=matlab_serial_date % 1) - \\\n",
    "                      datetime.timedelta(days=366)\n",
    "    return python_datetime\n",
    "\n",
    "def get_age(born_matlab_date, current_year):\n",
    "    return current_year - matlab_to_datetime(born_matlab_date).year\n",
    "\n",
    "new_data = [\n",
    "    # {\n",
    "        # image_path, gender, age\n",
    "    # }\n",
    "]\n",
    "\n",
    "for i in range(len(mat_data[0][0])):\n",
    "    new_data.append({\n",
    "        \"image_path\": mat_data[2][0][i][0],\n",
    "        \"age\": get_age(int(mat_data[0][0][i]), mat_data[1][0][i]),\n",
    "        \"gender\": mat_data[3][0][i]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in images:\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def read_image(path):\n",
    "    image = Image.open(os.path.join(DATA_DIR, path))\n",
    "    image = image.resize((256, 256))\n",
    "    return np.array(image)\n",
    "\n",
    "if not GET_IMAGES_FROM_PICKLE:\n",
    "    list_of_images = []\n",
    "    for i in range(len(df)):\n",
    "        list_of_images.append(read_image(df[\"image_path\"][i]))\n",
    "    with open(PICKLES_PATH + \"list_of_images.pickle\", \"wb\") as f:\n",
    "        pickle.dump(list_of_images, f)\n",
    "else:\n",
    "    with open(PICKLES_PATH + \"list_of_images.pickle\", \"rb\") as f:\n",
    "        list_of_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making every image 3 channels if it isnt already\n",
    "for i in range(len(list_of_images)):\n",
    "    if len(list_of_images[i].shape) != 3:\n",
    "        list_of_images[i] = np.stack((list_of_images[i],) * 3, axis=-1)\n",
    "\n",
    "# adding the images to the dataframe\n",
    "df[\"image\"] = list_of_images\n",
    "# drop na from the dataframe\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"image\"])\n",
    "X = np.concatenate(X)\n",
    "X = X.reshape(-1, 256, 256, 3)\n",
    "X = X / 255.0\n",
    "Y_age = df[\"age\"].values.astype('float32')\n",
    "Y_gender = df[\"gender\"].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59685, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test spliut:\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate Models\n",
    "\n",
    "## Gender Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 00:30:19.380475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 00:30:23.595557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79117 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.599522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79117 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.603183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79117 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:47:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.606840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79117 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:4e:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.610486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 79117 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.614106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 79117 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:90:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.617698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 79117 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:b7:00.0, compute capability: 8.0\n",
      "2023-03-06 00:30:23.621262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 79117 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "import tensorflow \n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy(\n",
    "#     devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\", \"/gpu:4\", \"/gpu:5\", \"/gpu:6\", \"/gpu:7\"],\n",
    "#     cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\n",
    "# )\n",
    "\n",
    "# with strategy.scope():\n",
    "\n",
    "input_layer = Input(shape=(256, 256, 3))\n",
    "CNN_1 = Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "CNN_1 = BatchNormalization()(CNN_1)\n",
    "CNN_2 = Conv2D(32, (3, 3), padding='same')(CNN_1)\n",
    "CNN_2 = BatchNormalization()(CNN_2)\n",
    "CNN_2 = Activation('relu')(CNN_2)\n",
    "CNN_2 = MaxPooling2D((2, 2), padding='same')(CNN_2)\n",
    "CNN_2 = Dropout(0.25)(CNN_2)\n",
    "CNN_3 = Conv2D(64, (3, 3), padding='same')(CNN_2)\n",
    "CNN_3 = BatchNormalization()(CNN_3)\n",
    "\n",
    "dense = Flatten()(CNN_3)\n",
    "output = Dense(1)(dense)\n",
    "\n",
    "gender_classification_model = Model(input_layer, output)\n",
    "\n",
    "gender_classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 00:31:05.851033: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-03-06 00:31:08.308310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8204\n",
      "2023-03-06 00:31:10.807325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-06 00:31:10.808379: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fc105854aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-06 00:31:10.808399: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808403: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808408: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808412: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808416: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (4): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808422: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (5): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808427: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (6): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.808431: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (7): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2023-03-06 00:31:10.813876: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-06 00:31:10.930553: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "        0: 80,\n",
    "        1: 20\n",
    "    }\n",
    "\n",
    "\n",
    "gender_classification_model.fit(X,\n",
    "                                Y_gender,\n",
    "                                epochs=100,\n",
    "                                batch_size=256,\n",
    "                                class_weight=class_weights,\n",
    "                                callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, min_lr=0.00000001, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
